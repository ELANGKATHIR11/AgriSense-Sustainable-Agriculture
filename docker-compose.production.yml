# =============================================================================
# AgriSense Production Docker Compose
# Part of Production Optimization Blueprint
# 
# This compose file sets up a complete production stack:
# - AgriSense API (FastAPI)
# - Redis (Cache & Celery broker)
# - Celery Workers (Background tasks)
# - Celery Beat (Scheduled tasks)
# - Flower (Celery monitoring)
# - Nginx (Reverse proxy - optional)
# 
# Usage:
#   docker-compose -f docker-compose.production.yml up -d
#   docker-compose -f docker-compose.production.yml logs -f
#   docker-compose -f docker-compose.production.yml down
# =============================================================================

version: '3.8'

services:
  # ===========================================================================
  # Redis - Cache & Message Broker
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: agrisense-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-}
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - agrisense-network

  # ===========================================================================
  # AgriSense API - Main Application
  # ===========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile.production
      args:
        INSTALL_ML: "true"
        ENABLE_GPU: "false"
    image: agrisense:production
    container_name: agrisense-api
    restart: unless-stopped
    ports:
      - "8004:8004"
    env_file:
      - .env.production
    environment:
      - REDIS_HOST=redis
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - DATABASE_URL=sqlite+aiosqlite:///./data/agrisense.db
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./uploads:/app/uploads
      - ./cache:/app/cache
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8004/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - agrisense-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # ===========================================================================
  # Celery Worker - Background Task Processing
  # ===========================================================================
  celery-worker:
    image: agrisense:production
    container_name: agrisense-celery-worker
    restart: unless-stopped
    command: celery -A agrisense_app.backend.celery_config worker --loglevel=info --concurrency=4
    env_file:
      - .env.production
    environment:
      - REDIS_HOST=redis
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - redis
      - api
    networks:
      - agrisense-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  # ===========================================================================
  # Celery Beat - Scheduled Tasks
  # ===========================================================================
  celery-beat:
    image: agrisense:production
    container_name: agrisense-celery-beat
    restart: unless-stopped
    command: celery -A agrisense_app.backend.celery_config beat --loglevel=info
    env_file:
      - .env.production
    environment:
      - REDIS_HOST=redis
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - redis
      - api
    networks:
      - agrisense-network

  # ===========================================================================
  # Flower - Celery Monitoring UI (Optional)
  # ===========================================================================
  flower:
    image: agrisense:production
    container_name: agrisense-flower
    restart: unless-stopped
    command: celery -A agrisense_app.backend.celery_config flower --port=5555
    ports:
      - "5555:5555"
    env_file:
      - .env.production
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    depends_on:
      - redis
      - celery-worker
    networks:
      - agrisense-network

  # ===========================================================================
  # Nginx - Reverse Proxy (Optional but recommended)
  # ===========================================================================
  nginx:
    image: nginx:alpine
    container_name: agrisense-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - api
    networks:
      - agrisense-network
    # Uncomment if you have SSL certificates
    # environment:
    #   - SSL_ENABLED=true

networks:
  agrisense-network:
    driver: bridge

volumes:
  redis-data:
    driver: local

# =============================================================================
# Production Deployment Checklist:
# 
# 1. ✅ Set up .env.production with secure credentials
# 2. ✅ Generate strong JWT_SECRET_KEY
# 3. ✅ Configure SSL certificates in config/nginx/ssl/
# 4. ✅ Set up firewall rules (allow 80, 443, block 8004, 6379)
# 5. ✅ Configure backup strategy (database, uploads)
# 6. ✅ Set up monitoring (Prometheus + Grafana)
# 7. ✅ Enable log aggregation (ELK Stack or similar)
# 8. ✅ Test disaster recovery procedures
# 9. ✅ Configure autoscaling policies
# 10. ✅ Set up CI/CD pipeline
# 
# =============================================================================

# =============================================================================
# Useful Commands:
# 
# Start all services:
#   docker-compose -f docker-compose.production.yml up -d
# 
# View logs:
#   docker-compose -f docker-compose.production.yml logs -f api
#   docker-compose -f docker-compose.production.yml logs -f celery-worker
# 
# Scale workers:
#   docker-compose -f docker-compose.production.yml up -d --scale celery-worker=4
# 
# Stop all services:
#   docker-compose -f docker-compose.production.yml down
# 
# Restart a service:
#   docker-compose -f docker-compose.production.yml restart api
# 
# Execute commands in container:
#   docker-compose -f docker-compose.production.yml exec api bash
#   docker-compose -f docker-compose.production.yml exec api python manage.py migrate
# 
# View resource usage:
#   docker-compose -f docker-compose.production.yml top
#   docker stats
# 
# Backup database:
#   docker-compose -f docker-compose.production.yml exec api python -m agrisense_app.scripts.backup_db
# 
# =============================================================================
